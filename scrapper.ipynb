{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "\n",
    "%pip install tqdm sqlalchemy tabula-py\n",
    "\n",
    "\n",
    "# Create the \"tables\" folder if it doesn't exist\n",
    "tables_folder_path = \"./tables\"\n",
    "if not os.path.exists(tables_folder_path):\n",
    "    os.makedirs(tables_folder_path)\n",
    "\n",
    "\n",
    "# Create the \"matrizes\" folder if it doesn't exist\n",
    "pdfs_folder_path = \"./courses_pdfs\"\n",
    "if not os.path.exists(pdfs_folder_path):\n",
    "    os.makedirs(pdfs_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Replace 'your_db_name', 'your_username', and 'your_password' with your PostgreSQL credentials\n",
    "db_name = 'gradeufop_db'\n",
    "username = 'postgres'\n",
    "password = '12345678'\n",
    "\n",
    "# Replace 'localhost' with the appropriate host if your PostgreSQL server is running on a different machine\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "\n",
    "# Create a connection to the PostgreSQL database\n",
    "conn_str = f\"postgresql://{username}:{password}@{host}:{port}/{db_name}\"\n",
    "engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def format_course_name(text):\n",
    "    # Remove accent marks\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "    # Replace symbols with a hyphen\n",
    "    text = re.sub(r'[^a-zA-Z0-9]+', '-', text)\n",
    "    \n",
    "    # Remove leading and trailing hyphens\n",
    "    text = text.strip('-')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca cursos e salva os .pdfs na pasta /matrizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "# Set up Chrome driver service\n",
    "chromedriver_path = (\n",
    "    \"./chromedriver\"  # Replace with the path to your chromedriver executable\n",
    ")\n",
    "service = Service(chromedriver_path)\n",
    "\n",
    "# Set up Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Navigate to the URL\n",
    "url = \"https://www.escolha.ufop.br/cursos\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Find elements with class \"ufop-glossary-row\"\n",
    "elements = driver.find_elements(By.CLASS_NAME, \"ufop-glossary-row\")\n",
    "\n",
    "# Extract the href links from child anchor 'a' tags\n",
    "links = []\n",
    "courses_dict = {\"id\": [], \"name\": []}\n",
    "for element in elements:\n",
    "    link_element = element.find_element(By.TAG_NAME, \"a\")\n",
    "    href = link_element.get_attribute(\"href\")\n",
    "    links.append(href)\n",
    "\n",
    "    courses_dict[\"name\"].append(link_element.text)\n",
    "    courses_dict[\"id\"].append(format_course_name(link_element.text))\n",
    "\n",
    "\n",
    "indexes_to_delete = []\n",
    "course_pdfs = []\n",
    "\n",
    "# Navigate to each link and download PDF files\n",
    "print(\"Buscando os links .pdf ...\")\n",
    "with tqdm(total=len(links), desc=\"Progresso\", ascii=True) as pbar:\n",
    "    for i, link in enumerate(links):\n",
    "        driver.get(link)\n",
    "\n",
    "        matriz_elements = driver.find_elements(\n",
    "            By.CLASS_NAME, \"field-name-field-matriz-curricular\"\n",
    "        )\n",
    "\n",
    "        for element in matriz_elements:\n",
    "            link_elements = element.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "            if len(link_elements) == 1:\n",
    "                href = link_elements[0].get_attribute(\"href\")\n",
    "                course_pdfs.append({\"course\": courses_dict[\"id\"][i], \"link\": href})\n",
    "                continue\n",
    "\n",
    "            for link_element in link_elements:\n",
    "                href = link_element.get_attribute(\"href\")\n",
    "                course_type = link_element.text\n",
    "                course_name = f\"{courses_dict['name'][i]} ({course_type})\"\n",
    "                course_id = format_course_name(course_name)\n",
    "                courses_dict[\"name\"].append(course_name)\n",
    "                courses_dict[\"id\"].append(format_course_name(course_name))\n",
    "\n",
    "                course_pdfs.append({\"course\": course_id, \"link\": href})\n",
    "            indexes_to_delete.append(i)\n",
    "\n",
    "        pbar.set_postfix(curso=f\"{courses_dict['name'][i]}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "courses_dict[\"id\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"id\"]) if i not in indexes_to_delete\n",
    "]\n",
    "courses_dict[\"name\"] = [\n",
    "    item for i, item in enumerate(courses_dict[\"name\"]) if i not in indexes_to_delete\n",
    "]\n",
    "\n",
    "valid_pdf_substrings = [\".pdf\", \"codCurso=\"]\n",
    "for pdf in course_pdfs:\n",
    "    import os\n",
    "\n",
    "for pdf in course_pdfs:\n",
    "    if any(text in pdf[\"link\"] for text in valid_pdf_substrings):\n",
    "        response = requests.get(pdf[\"link\"])\n",
    "        parsed_url = urlparse(pdf[\"link\"])\n",
    "        filename = f\"{pdf['course']}.pdf\"\n",
    "        file_path = os.path.join(pdfs_folder_path, filename)\n",
    "\n",
    "        # Check if the file already exists in the folder\n",
    "        if not os.path.exists(file_path):\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"{filename} salvo com sucesso.\")\n",
    "        else:\n",
    "            print(f\"{filename} já existe no diretório. Pulando...\")\n",
    "\n",
    "\n",
    "# Quit the driver\n",
    "driver.quit()\n",
    "\n",
    "courses_df = pd.DataFrame(courses_dict).sort_values(by='id', ascending = True)\n",
    "courses_df['created_at'] = datetime.now()\n",
    "courses_df.to_csv(f\"{tables_folder_path}/course.csv\", index=False)\n",
    "\n",
    "# Save courses table in database\n",
    "courses_df.to_sql('course', engine, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "URL = \"https://zeppelin10.ufop.br/HorarioAulas/\"\n",
    "\n",
    "desired_departments = [\"DECSI\", \"DECEA\", \"DEELT\", \"DEENP\", \"DEETE\"]\n",
    "semester = \"23.1\"\n",
    "\n",
    "\n",
    "def get_HTML_content(URL, department):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(URL)\n",
    "    elem = driver.find_element(By.XPATH, \"//*[text()='{}']\".format(department))\n",
    "    elem.click()\n",
    "    URL = driver.current_url\n",
    "    html_source = driver.page_source\n",
    "    soup = BeautifulSoup(html_source, \"lxml\")\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "\n",
    "def parse_schedule_string(schedule_string):\n",
    "    entries = []\n",
    "    \n",
    "    if schedule_string == '':\n",
    "        return entries\n",
    "    \n",
    "    schedule_parts = schedule_string.split(\" / \")\n",
    "    \n",
    "    if len(schedule_parts) == 0:\n",
    "        schedule_parts.append(schedule_string)\n",
    "\n",
    "    for part in schedule_parts:\n",
    "        day, time_info = part.split(\" \")\n",
    "        start_time, end_time = time_info.split(\"-\")\n",
    "        class_type = end_time[-2]  # T for theoretical, P for practical\n",
    "        end_time = end_time[:-3]  # Remove the class type from end_time\n",
    "\n",
    "        entry = {\n",
    "            \"day_of_week\": day,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "            \"class_type\": class_type,\n",
    "        }\n",
    "        entries.append(entry)\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "def get_field_list(html_content, field):\n",
    "    field_list = []\n",
    "    table = html_content.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            if field == \"descricao\":\n",
    "                span = tr.find(\n",
    "                    \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, \"disciplina\")}\n",
    "                )\n",
    "                title = span.find_parent(\"a\").get(\n",
    "                    \"title\"\n",
    "                )  # Extract the 'title' attribute of the parent <a> tag\n",
    "                field_list.append(title)\n",
    "                continue\n",
    "\n",
    "            span = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:{}\".format(i, field)}\n",
    "            )\n",
    "            field_list.append(span.text)\n",
    "\n",
    "    return field_list\n",
    "\n",
    "\n",
    "def get_departments():\n",
    "    r = requests.get(URL)\n",
    "    departments_table = []\n",
    "    departments_list = []\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")  # Use 'html.parser' as the parser\n",
    "\n",
    "    # Find the table with the specified id\n",
    "    table = soup.find(\"table\", {\"id\": \"formPrincipal:tabela\"})\n",
    "    if table:\n",
    "        tbody = table.find(\"tbody\")\n",
    "\n",
    "        # Find all <tr> elements within <tbody>\n",
    "        tr_elements = tbody.find_all(\"tr\")\n",
    "\n",
    "        for i, tr in enumerate(tr_elements):\n",
    "            tableCode = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:codigoDepartamento\".format(i)}\n",
    "            )\n",
    "            tableName = tr.find(\n",
    "                \"span\", {\"id\": \"formPrincipal:tabela:{}:descricao\".format(i)}\n",
    "            )\n",
    "            # if tableCode and tableCode.text.strip() in desired_departments:\n",
    "            #     departments_table.append(\n",
    "            #         {\"id\": tableCode.text.strip(), \"name\": tableName.text.strip()}\n",
    "            #     )\n",
    "            #     departments_list.append(tableCode.text.strip())\n",
    "            departments_table.append(\n",
    "                {\"id\": tableCode.text.strip(), \"name\": tableName.text.strip()}\n",
    "            )\n",
    "            departments_list.append(tableCode.text.strip())\n",
    "\n",
    "        departments_df = pd.DataFrame(departments_table)\n",
    "        departments_df[\"created_at\"] = datetime.now()\n",
    "        return departments_df, departments_list\n",
    "\n",
    "\n",
    "def get_discipline_tables(departments_list):\n",
    "    discipline_dict = {\"id\": [], \"name\": [], \"description\": [], \"department_id\": []}\n",
    "    class_dict = {\n",
    "        \"id\": [],\n",
    "        \"class_number\": [],\n",
    "        \"discipline_id\": [],\n",
    "        \"professor\": [],\n",
    "    }\n",
    "    schedule_dict = {\n",
    "        \"id\": [],\n",
    "        \"discipline_class_id\": [],\n",
    "        \"day_of_week\": [],\n",
    "        \"start_time\": [],\n",
    "        \"end_time\": [],\n",
    "        \"class_type\": [],\n",
    "    }\n",
    "\n",
    "    for department in departments_list:\n",
    "        if department not in desired_departments:\n",
    "            continue\n",
    "\n",
    "        print(f\"Buscando {department}\")\n",
    "        html_content = get_HTML_content(URL, department)\n",
    "        columns_list = [\n",
    "            \"codigo\",\n",
    "            \"disciplina\",\n",
    "            \"descricao\",\n",
    "            \"turma\",\n",
    "            \"horario\",\n",
    "            \"professores\",\n",
    "        ]\n",
    "        columns_dict_list = {}\n",
    "\n",
    "        for column_name in columns_list:\n",
    "            field = get_field_list(html_content, column_name)\n",
    "            columns_dict_list[column_name] = field\n",
    "\n",
    "        for i in range(len(columns_dict_list[\"codigo\"])):\n",
    "            discipline_dict[\"id\"].append(columns_dict_list[\"codigo\"][i])\n",
    "            discipline_dict[\"name\"].append(columns_dict_list[\"disciplina\"][i])\n",
    "            discipline_dict[\"description\"].append(columns_dict_list[\"descricao\"][i])\n",
    "            discipline_dict[\"department_id\"].append(department)\n",
    "\n",
    "            discipline_class_id = str(uuid.uuid4())\n",
    "            class_dict[\"id\"].append(discipline_class_id)\n",
    "            class_dict[\"class_number\"].append(columns_dict_list[\"turma\"][i])\n",
    "            class_dict[\"discipline_id\"].append(columns_dict_list[\"codigo\"][i])\n",
    "            class_dict[\"professor\"].append(columns_dict_list[\"professores\"][i])\n",
    "\n",
    "            schedule_entries = parse_schedule_string(columns_dict_list[\"horario\"][i])\n",
    "            for entry in schedule_entries:\n",
    "                schedule_dict[\"id\"].append(str(uuid.uuid4()))\n",
    "                schedule_dict[\"discipline_class_id\"].append(discipline_class_id)\n",
    "                schedule_dict[\"day_of_week\"].append(entry[\"day_of_week\"])\n",
    "                schedule_dict[\"start_time\"].append(entry[\"start_time\"])\n",
    "                schedule_dict[\"end_time\"].append(entry[\"end_time\"])\n",
    "                schedule_dict[\"class_type\"].append(entry[\"class_type\"])\n",
    "\n",
    "    discipline_df = pd.DataFrame(discipline_dict).drop_duplicates()\n",
    "    class_df = pd.DataFrame(class_dict)\n",
    "    schedule_df = pd.DataFrame(schedule_dict)\n",
    "\n",
    "    currentTime = datetime.now()\n",
    "\n",
    "    discipline_df[\"created_at\"] = currentTime\n",
    "    class_df[\"created_at\"] = currentTime\n",
    "    class_df[\"semester\"] = semester\n",
    "    schedule_df[\"created_at\"] = currentTime\n",
    "\n",
    "    return discipline_df, class_df, schedule_df\n",
    "\n",
    "\n",
    "department_df, departments_list = get_departments()\n",
    "department_df.to_csv(f\"{tables_folder_path}/department.csv\", index=False)\n",
    "department_df.to_sql(\"department\", engine, index=False, if_exists=\"replace\")\n",
    "\n",
    "(\n",
    "    discipline_df,\n",
    "    discipline_class_df,\n",
    "    discipline_class_schedule_df,\n",
    ") = get_discipline_tables(departments_list)\n",
    "discipline_df.to_csv(f\"{tables_folder_path}/discipline.csv\", index=False)\n",
    "discipline_df.to_sql(\"discipline\", engine, index=False, if_exists=\"replace\")\n",
    "\n",
    "discipline_class_df.to_csv(f\"{tables_folder_path}/discipline_class.csv\", index=False)\n",
    "discipline_class_df.to_sql(\"discipline_class\", engine, index=False, if_exists=\"replace\")\n",
    "\n",
    "discipline_class_schedule_df.to_csv(\n",
    "    f\"{tables_folder_path}/discipline_class_schedule.csv\", index=False\n",
    ")\n",
    "discipline_class_schedule_df.to_sql(\n",
    "    \"discipline_class_schedule\", engine, index=False, if_exists=\"replace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "import re\n",
    "\n",
    "code_pattern = r\"[A-Z]{3}\\d{3}\"\n",
    "subject_pattern = r\"\\b[A-Z]+\\b\"\n",
    "classes_pattern = r\"^(T P|T|P)$\"\n",
    "prerequisite_pattern = r\"[A-Z]{3}\\d{3}|\\d+\\s+horas\"\n",
    "chs_che_pattern = r\"^\\d+\\/\\d+$\"\n",
    "\n",
    "\n",
    "def get_col_idx(df_value, pattern):\n",
    "    indexes = []\n",
    "    for i, item in enumerate(df_value):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        match = re.search(pattern, str(item), re.UNICODE)\n",
    "        if match is not None:\n",
    "            indexes.append(i)\n",
    "\n",
    "    return indexes\n",
    "\n",
    "\n",
    "def replace_carriage_return(arr):\n",
    "    series = pd.Series(arr)\n",
    "\n",
    "    # Replace '\\r' with an empty string in the Series values\n",
    "    series = series.astype(str).str.replace(r\"\\r\", \"\")\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "def get_prerequisites(df_value):\n",
    "    prerequisites = []\n",
    "    prereq_idx = get_col_idx(df_value, prerequisite_pattern)\n",
    "    if len(prereq_idx) > 0:\n",
    "        prerequisites = [df_value[i] for i in prereq_idx]\n",
    "\n",
    "    return format_prerequisites(prerequisites)\n",
    "\n",
    "\n",
    "def get_discipline(df_value):\n",
    "    subject_idx = get_col_idx(df_value, subject_pattern)\n",
    "    if len(subject_idx) > 0:\n",
    "        return re.sub(code_pattern, \"\", df_value[subject_idx[0]])\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_chs_che(df_value):\n",
    "    chs_che_idx = get_col_idx(df_value, chs_che_pattern)\n",
    "\n",
    "    if len(chs_che_idx) > 0:\n",
    "        chs_che_list = df_value[chs_che_idx[0]].split(\"/\")\n",
    "        return tuple(map(int, chs_che_list))\n",
    "\n",
    "    return (\"\", \"\")\n",
    "\n",
    "\n",
    "def get_classes(df_value, classes_idx):\n",
    "    classes = []\n",
    "    if len(classes_idx) > 0:\n",
    "        classes = [df_value[i] for i in classes_idx]\n",
    "        return \" \".join(classes)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_period(df_value, eletiva):\n",
    "    if eletiva or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_period2(df_value, mandatory):\n",
    "    if not mandatory or not df_value[0]:\n",
    "        return \"\"\n",
    "\n",
    "    for item in reversed(df_value):\n",
    "        if item:\n",
    "            return int(item)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_cha(df_value, chs):\n",
    "    if not chs:\n",
    "        return \"\"\n",
    "\n",
    "    chs_alt = chs * 1.2\n",
    "\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    for text in df_value:\n",
    "        try:\n",
    "            formatted_text = int(text)\n",
    "            if formatted_text == chs or formatted_text == chs_alt:\n",
    "                return formatted_text\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def format_prerequisites(df_value):\n",
    "    if len(df_value) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    requisites = []\n",
    "    for text in df_value:\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        matches = re.findall(code_pattern, text)\n",
    "        requisites.extend(matches)\n",
    "\n",
    "    joined_matches = \" \".join(requisites)\n",
    "    return joined_matches\n",
    "\n",
    "\n",
    "def get_formatted_df(df, eletiva):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\n",
    "        \"codigo\": [],\n",
    "        \"disciplina\": [],\n",
    "        \"prerequisitos\": [],\n",
    "        \"chs\": [],\n",
    "        \"che\": [],\n",
    "        \"cha\": [],\n",
    "        \"aulas\": [],\n",
    "        \"periodo\": [],\n",
    "    }\n",
    "    ideal_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    ideal_columns = ideal_df.columns.to_list()\n",
    "\n",
    "    column_names = df.columns.tolist()\n",
    "    disc_indexes = [i for i, item in enumerate(column_names) if \"DISCIPLINAS\" in item]\n",
    "\n",
    "    iterIdx = -1\n",
    "    classes_idx = []\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            classes_idx = get_col_idx(value, classes_pattern)\n",
    "            ideal_df.at[0, ideal_columns[0]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[1]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[2]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[3]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[4]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[5]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[6]] = \"\"\n",
    "            ideal_df.at[0, ideal_columns[7]] = \"\"\n",
    "            continue\n",
    "\n",
    "        chs, che = get_chs_che(value)\n",
    "        ideal_df.at[idx, ideal_columns[0]] = value[0]\n",
    "        ideal_df.at[idx, ideal_columns[1]] = get_discipline(value)\n",
    "        ideal_df.at[idx, ideal_columns[2]] = get_prerequisites(value)\n",
    "        ideal_df.at[idx, ideal_columns[3]] = chs\n",
    "        ideal_df.at[idx, ideal_columns[4]] = che\n",
    "        ideal_df.at[idx, ideal_columns[5]] = get_cha(value, chs)\n",
    "        ideal_df.at[idx, ideal_columns[6]] = get_classes(value, classes_idx)\n",
    "        ideal_df.at[idx, ideal_columns[7]] = get_period(value, eletiva)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        ideal_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(ideal_df.values[iterIdx], ideal_df.values[idx])\n",
    "        ]\n",
    "\n",
    "    ideal_df.drop(ideal_df[ideal_df[\"codigo\"] == \"\"].index, inplace=True)\n",
    "    ideal_df[[\"chs\", \"che\", \"cha\"]] = ideal_df[[\"chs\", \"che\", \"cha\"]].astype(int)\n",
    "    ideal_df[\"eletiva\"] = eletiva\n",
    "\n",
    "    return ideal_df\n",
    "\n",
    "\n",
    "def get_prerequisite_df(discipline_course_df):\n",
    "    prerequisite_df = pd.concat(\n",
    "        discipline_course_df.apply(create_prerequisite_rows, axis=1).tolist(),\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    prerequisite_df[\"created_at\"] = datetime.now()\n",
    "    return prerequisite_df\n",
    "\n",
    "\n",
    "def create_prerequisite_rows(row):\n",
    "    prerequisites = row[\"prerequisites\"].split()\n",
    "    if len(prerequisites):\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"id\": [str(uuid.uuid4()) for _ in range(len(prerequisites))],\n",
    "                \"discipline_course_id\": [row[\"id\"] for _ in range(len(prerequisites))],\n",
    "                \"prerequisite_discipline_id\": prerequisites,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def get_discipline_course_tables(df, course_id, mandatory):\n",
    "    df = df.replace({r\"\\r\": \" \"}, regex=True)\n",
    "    df_struct = {\"id\": [], \"discipline_id\": [], \"period\": [], \"prerequisites\": []}\n",
    "    discipline_course_df = pd.DataFrame(data=df_struct)\n",
    "\n",
    "    ideal_columns = discipline_course_df.columns.to_list()\n",
    "\n",
    "    column_names = df.columns.tolist()\n",
    "    disc_indexes = [i for i, item in enumerate(column_names) if \"DISCIPLINAS\" in item]\n",
    "\n",
    "    iterIdx = -1\n",
    "\n",
    "    for idx, value in enumerate(df.values):\n",
    "        if idx == 0:\n",
    "            iterIdx = -1\n",
    "            discipline_course_df.at[0, \"id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"discipline_id\"] = \"\"\n",
    "            discipline_course_df.at[0, \"period\"] = \"\"\n",
    "            discipline_course_df.at[0, \"prerequisites\"] = \"\"\n",
    "            continue\n",
    "\n",
    "        discipline_course_df.at[idx, \"id\"] = str(uuid.uuid4())\n",
    "        discipline_course_df.at[idx, \"discipline_id\"] = value[0]\n",
    "        discipline_course_df.at[idx, \"period\"] = get_period2(value, mandatory)\n",
    "        discipline_course_df.at[idx, \"prerequisites\"] = get_prerequisites(value)\n",
    "\n",
    "        if value[0] != \"\":\n",
    "            iterIdx = -1\n",
    "            continue\n",
    "\n",
    "        if iterIdx == -1:\n",
    "            iterIdx = idx - 1\n",
    "\n",
    "        discipline_course_df.loc[iterIdx, :] = [\n",
    "            f\"{item1} {item2}\".strip()\n",
    "            for item1, item2 in zip(\n",
    "                discipline_course_df.values[iterIdx], discipline_course_df.values[idx]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    discipline_course_df.drop(\n",
    "        discipline_course_df[discipline_course_df[\"discipline_id\"] == \"\"].index,\n",
    "        inplace=True,\n",
    "    )\n",
    "    discipline_course_df[\"mandatory\"] = mandatory\n",
    "    discipline_course_df[\"course_id\"] = course_id\n",
    "    prerequisite_df = pd.DataFrame()\n",
    "    if not discipline_course_df.empty:\n",
    "        prerequisite_df = get_prerequisite_df(discipline_course_df)\n",
    "\n",
    "    discipline_course_df.drop(\"prerequisites\", axis=1)\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "def save_table_to_csv(df):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    filename = \"table.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Table saved as {filename}\")\n",
    "\n",
    "\n",
    "def save_table_to_json(df):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    filename = \"table.json\"\n",
    "    df.to_json(filename, orient=\"records\")\n",
    "    print(f\"Table saved as {filename}\")\n",
    "\n",
    "\n",
    "def scrape_table_from_pdf(pdf_path):\n",
    "    # Read the table from the PDF file\n",
    "    df_list = tabula.read_pdf(pdf_path, pages=\"all\")\n",
    "\n",
    "    course_id = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "    discipline_course_dfs = []\n",
    "    prerequisite_dfs = []\n",
    "\n",
    "    for df in df_list:\n",
    "        df.fillna(\"\", inplace=True)\n",
    "        # Filter and select the desired columns based on the header\n",
    "        header = df.columns.to_list()\n",
    "        eletivas_column = next(\n",
    "            (col for col in header if \"DISCIPLINAS ELETIVAS\" in col), None\n",
    "        )\n",
    "        obrigatorias_column = next(\n",
    "            (col for col in header if \"DISCIPLINAS OBRIGATÓRIAS\" in col), None\n",
    "        )\n",
    "\n",
    "        if \"DISCIPLINAS OBRIGATÓRIAS\" in header:\n",
    "            discipline_course_df, prerequiste_df = get_discipline_course_tables(\n",
    "                df, course_id, True\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequiste_df)\n",
    "\n",
    "        elif (\n",
    "            \"DISCIPLINAS ELETIVAS\" in header\n",
    "            or \"DISCIPLINAS ELETIVAS PRÉ-REQUISITO\" in header\n",
    "        ):\n",
    "            discipline_course_df, prerequiste_df = get_discipline_course_tables(\n",
    "                df, course_id, False\n",
    "            )\n",
    "            discipline_course_dfs.append(discipline_course_df)\n",
    "            prerequisite_dfs.append(prerequiste_df)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    combined_discipline_course_df = pd.concat(discipline_course_dfs, ignore_index=True)\n",
    "\n",
    "    combined_prerequisite_df = pd.concat(prerequisite_dfs, ignore_index=True)\n",
    "    discipline_course_df = combined_discipline_course_df[\n",
    "        combined_discipline_course_df[\"discipline_id\"].isin(discipline_df[\"id\"])\n",
    "    ]\n",
    "\n",
    "    prerequisite_df = combined_prerequisite_df\n",
    "    if not combined_prerequisite_df.empty:\n",
    "        prerequisite_df = combined_prerequisite_df[\n",
    "            combined_prerequisite_df[\"discipline_course_id\"].isin(\n",
    "                discipline_course_df[\"id\"]\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    return discipline_course_df, prerequisite_df\n",
    "\n",
    "\n",
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "\n",
    "for pdf_file in [\n",
    "    \"./courses_pdfs/engenharia-de-computacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-de-producao-jm.pdf\",\n",
    "    \"./courses_pdfs/sistemas-de-informacao.pdf\",\n",
    "    \"./courses_pdfs/engenharia-eletrica.pdf\",\n",
    "]:\n",
    "    print(f\"Buscando {pdf_file}\")\n",
    "    discipline_course_df, prerequisite_df = scrape_table_from_pdf(pdf_file)\n",
    "    discipline_course_df.to_csv(\n",
    "        f\"{tables_folder_path}/discipline_course.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/discipline_course.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    discipline_course_df.to_sql(\n",
    "        \"discipline_course\", con=engine, if_exists=\"append\", index=False\n",
    "    )\n",
    "\n",
    "    prerequisite_df.to_csv(\n",
    "        f\"{tables_folder_path}/prerequisite.csv\",\n",
    "        mode=\"a\",\n",
    "        header=not os.path.exists(f\"{tables_folder_path}/prerequisite.csv\"),\n",
    "        index=False,\n",
    "    )\n",
    "    prerequisite_df.to_sql(\"prerequisite\", con=engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "# discipline_course_df, prerequisite_df = scrape_table_from_pdf(\n",
    "#     \"./courses_pdfs/fisica-bacharelado.pdf\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(pdfs_folder_path)\n",
    "pdf_files = [\n",
    "    os.path.join(pdfs_folder_path, file) for file in files if file.endswith(\".pdf\")\n",
    "]\n",
    "print(len(pdf_files))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
